{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda95702",
   "metadata": {
    "papermill": {
     "duration": 0.003957,
     "end_time": "2025-11-08T05:52:22.121796",
     "exception": false,
     "start_time": "2025-11-08T05:52:22.117839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Kaggle Playground "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924a9bd",
   "metadata": {
    "papermill": {
     "duration": 0.002701,
     "end_time": "2025-11-08T05:52:22.127727",
     "exception": false,
     "start_time": "2025-11-08T05:52:22.125026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Problem Statement / Real World Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c816bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T05:52:22.134998Z",
     "iopub.status.busy": "2025-11-08T05:52:22.134708Z",
     "iopub.status.idle": "2025-11-08T05:52:32.223752Z",
     "shell.execute_reply": "2025-11-08T05:52:32.222683Z"
    },
    "papermill": {
     "duration": 10.094922,
     "end_time": "2025-11-08T05:52:32.225572",
     "exception": false,
     "start_time": "2025-11-08T05:52:22.130650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 1. Importing Libraries ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Models\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Notebook settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b003c03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T05:52:32.233939Z",
     "iopub.status.busy": "2025-11-08T05:52:32.232861Z",
     "iopub.status.idle": "2025-11-08T05:52:32.239657Z",
     "shell.execute_reply": "2025-11-08T05:52:32.238576Z"
    },
    "papermill": {
     "duration": 0.012191,
     "end_time": "2025-11-08T05:52:32.241164",
     "exception": false,
     "start_time": "2025-11-08T05:52:32.228973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 11: 3-Model CV Ensemble (LGBM+XGB+CAT) with Advanced FE\n",
      "--- 1. Loading Data ---\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Configuration ---\n",
    "class Config:\n",
    "    \"\"\"Configuration class for hyperparameters and settings\"\"\"\n",
    "    N_SPLITS = 5\n",
    "    SEED = 42\n",
    "    TARGET = 'loan_paid_back'\n",
    "\n",
    "config = Config()\n",
    "\n",
    "print(\"Version 11: 3-Model CV Ensemble (LGBM+XGB+CAT) with Advanced FE\")\n",
    "print(f\"--- 1. Loading Data ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f53f45c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T05:52:32.249239Z",
     "iopub.status.busy": "2025-11-08T05:52:32.248358Z",
     "iopub.status.idle": "2025-11-08T05:52:34.469341Z",
     "shell.execute_reply": "2025-11-08T05:52:34.468232Z"
    },
    "papermill": {
     "duration": 2.226623,
     "end_time": "2025-11-08T05:52:34.471163",
     "exception": false,
     "start_time": "2025-11-08T05:52:32.244540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (593994, 13), Test shape: (254569, 12)\n",
      "--- 2. Defining Preprocessing & Feature Engineering ---\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "TRAIN_PATH = \"/kaggle/input/playground-series-s5e11/train.csv\"\n",
    "TEST_PATH = \"/kaggle/input/playground-series-s5e11/test.csv\"\n",
    "SUBMISSION_PATH = \"/kaggle/input/playground-series-s5e11/sample_submission.csv\"\n",
    "\n",
    "# Load the datasets\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "sample_submission = pd.read_csv(SUBMISSION_PATH)\n",
    "\n",
    "print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
    "print(\"--- 2. Defining Preprocessing & Feature Engineering ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0f75649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T05:52:34.479190Z",
     "iopub.status.busy": "2025-11-08T05:52:34.478926Z",
     "iopub.status.idle": "2025-11-08T05:52:34.501601Z",
     "shell.execute_reply": "2025-11-08T05:52:34.500652Z"
    },
    "papermill": {
     "duration": 0.028288,
     "end_time": "2025-11-08T05:52:34.503090",
     "exception": false,
     "start_time": "2025-11-08T05:52:34.474802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def complete_feature_engineering(df):\n",
    "    \"\"\"\n",
    "    Comprehensive feature engineering pipeline for loan prediction\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. FINANCIAL RATIOS \n",
    "    df['loan_to_income_ratio'] = df['loan_amount'] / (df['annual_income'] + 1)\n",
    "    df['monthly_income'] = df['annual_income'] / 12\n",
    "    # Simplified approximation from source\n",
    "    df['monthly_payment_estimate'] = (df['loan_amount'] * df['interest_rate']) / 100  \n",
    "    df['payment_to_income_ratio'] = df['monthly_payment_estimate'] / (df['monthly_income'] + 1)\n",
    "    df['current_debt_amount'] = df['debt_to_income_ratio'] * df['annual_income']\n",
    "    df['total_debt_with_loan'] = df['current_debt_amount'] + df['loan_amount']\n",
    "    df['new_debt_to_income'] = df['total_debt_with_loan'] / (df['annual_income'] + 1)\n",
    "    df['debt_increase_ratio'] = df['new_debt_to_income'] / (df['debt_to_income_ratio'] + 1e-6)\n",
    "    df['disposable_income'] = df['annual_income'] - df['current_debt_amount']\n",
    "    df['disposable_income_ratio'] = df['disposable_income'] / (df['annual_income'] + 1)\n",
    "    df['loan_to_disposable_income'] = df['loan_amount'] / (df['disposable_income'] + 1)\n",
    "    df['monthly_disposable_income'] = df['disposable_income'] / 12\n",
    "    df['payment_to_disposable_ratio'] = df['monthly_payment_estimate'] / (df['monthly_disposable_income'] + 1)\n",
    "    df['annual_payment_burden'] = df['monthly_payment_estimate'] * 12\n",
    "    df['payment_burden_ratio'] = df['annual_payment_burden'] / (df['annual_income'] + 1)\n",
    "\n",
    "    # 2. CREDIT SCORE FEATURES \n",
    "    df['credit_score_normalized'] = df['credit_score'] / 850\n",
    "    df['credit_risk_score'] = 1 - df['credit_score_normalized']\n",
    "    df['credit_score_squared'] = df['credit_score'] ** 2\n",
    "    df['credit_score_log'] = np.log1p(df['credit_score'])\n",
    "    df['credit_category'] = pd.cut(df['credit_score'], bins=[0, 580, 670, 740, 800, 850],\n",
    "                                 labels=['poor', 'fair', 'good', 'very_good', 'excellent'])\n",
    "    df['credit_income_interaction'] = df['credit_score'] * df['annual_income']\n",
    "    df['credit_times_dti'] = df['credit_score'] * df['debt_to_income_ratio']\n",
    "    df['credit_loan_interaction'] = df['credit_score'] * df['loan_amount']\n",
    "\n",
    "    # 3. INTEREST RATE FEATURES \n",
    "    df['high_interest_flag'] = (df['interest_rate'] > df['interest_rate'].median()).astype(int)\n",
    "    df['very_high_interest'] = (df['interest_rate'] > df['interest_rate'].quantile(0.75)).astype(int)\n",
    "    df['low_interest_flag'] = (df['interest_rate'] < df['interest_rate'].quantile(0.25)).astype(int)\n",
    "    df['total_interest_cost'] = df['loan_amount'] * df['interest_rate'] / 100\n",
    "    df['interest_burden'] = df['total_interest_cost'] / (df['annual_income'] + 1)\n",
    "    df['interest_credit_mismatch'] = df['interest_rate'] * (1 - df['credit_score_normalized'])\n",
    "    df['interest_credit_ratio'] = df['interest_rate'] / (df['credit_score'] / 100)\n",
    "    df['interest_rate_squared'] = df['interest_rate'] ** 2\n",
    "\n",
    "    # 4. RISK SCORES \n",
    "    df['risk_score_v1'] = (df['debt_to_income_ratio'] * 0.25 + df['loan_to_income_ratio'] * 0.25 +\n",
    "                            df['credit_risk_score'] * 0.30 + (df['interest_rate'] / 100) * 0.20)\n",
    "    df['risk_score_v2'] = (df['payment_to_income_ratio'] * 0.40 + df['new_debt_to_income'] * 0.35 +\n",
    "                            df['interest_burden'] * 0.25)\n",
    "    df['affordability_score'] = (df['credit_score_normalized'] * 0.40 +\n",
    "                                (1 - df['debt_to_income_ratio']) * 0.30 +\n",
    "                                df['disposable_income_ratio'] * 0.30)\n",
    "    df['financial_health_score'] = df['affordability_score'] * 0.60 - df['risk_score_v1'] * 0.40\n",
    "\n",
    "    # 5. LOAN AMOUNT FEATURES \n",
    "    df['loan_size'] = pd.cut(df['loan_amount'], bins=[0, 10000, 20000, 30000, np.inf],\n",
    "                             labels=['small', 'medium', 'large', 'very_large'])\n",
    "    df['loan_amount_squared'] = df['loan_amount'] ** 2\n",
    "    df['loan_amount_log'] = np.log1p(df['loan_amount'])\n",
    "    df['annual_income_log'] = np.log1p(df['annual_income'])\n",
    "    df['loan_amount_sqrt'] = np.sqrt(df['loan_amount'])\n",
    "\n",
    "    # 6. BINNING FEATURES\n",
    "    df['income_decile'] = pd.qcut(df['annual_income'], q=10, labels=False, duplicates='drop')\n",
    "    df['credit_decile'] = pd.qcut(df['credit_score'], q=10, labels=False, duplicates='drop')\n",
    "    df['loan_decile'] = pd.qcut(df['loan_amount'], q=10, labels=False, duplicates='drop')\n",
    "    df['dti_decile'] = pd.qcut(df['debt_to_income_ratio'], q=10, labels=False, duplicates='drop')\n",
    "    df['interest_decile'] = pd.qcut(df['interest_rate'], q=10, labels=False, duplicates='drop')\n",
    "\n",
    "    # 7. INTERACTION FEATURES \n",
    "    df['income_x_credit'] = df['annual_income'] * df['credit_score']\n",
    "    df['dti_x_interest'] = df['debt_to_income_ratio'] * df['interest_rate']\n",
    "    df['loan_x_interest'] = df['loan_amount'] * df['interest_rate']\n",
    "    df['income_x_dti'] = df['annual_income'] * df['debt_to_income_ratio']\n",
    "    df['income_credit_loan'] = (df['annual_income'] * df['credit_score']) / (df['loan_amount'] + 1)\n",
    "    df['dti_interest_credit'] = (df['debt_to_income_ratio'] * df['interest_rate']) / (df['credit_score_normalized'] + 1e-6)\n",
    "\n",
    "    # 8. GRADE FEATURES \n",
    "    df['grade'] = df['grade_subgrade'].str[0]\n",
    "    df['subgrade_num'] = pd.to_numeric(df['grade_subgrade'].str[1:], errors='coerce')\n",
    "    grade_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7}\n",
    "    df['grade_numeric'] = df['grade'].map(grade_map)\n",
    "    df['full_grade_score'] = df['grade_numeric'] * 10 + df['subgrade_num']\n",
    "    df['grade_credit_ratio'] = df['full_grade_score'] / (df['credit_score'] / 100)\n",
    "\n",
    "    # 9. STATISTICAL AGGREGATIONS \n",
    "    financial_metrics = ['debt_to_income_ratio', 'loan_to_income_ratio', 'payment_to_income_ratio']\n",
    "    df['mean_financial_metrics'] = df[financial_metrics].mean(axis=1)\n",
    "    df['max_financial_burden'] = df[financial_metrics].max(axis=1)\n",
    "    df['min_financial_burden'] = df[financial_metrics].min(axis=1)\n",
    "    df['std_financial_metrics'] = df[financial_metrics].std(axis=1)\n",
    "\n",
    "    # 10. CATEGORICAL COMBINATIONS \n",
    "    df['gender_marital'] = df['gender'] + '_' + df['marital_status']\n",
    "    df['education_employment'] = df['education_level'] + '_' + df['employment_status']\n",
    "    df['gender_education'] = df['gender'] + '_' + df['education_level']\n",
    "    df['marital_employment'] = df['marital_status'] + '_' + df['employment_status']\n",
    "    df['purpose_grade'] = df['loan_purpose'] + '_' + df['grade']\n",
    "    df['employment_purpose'] = df['employment_status'] + '_' + df['loan_purpose']\n",
    "\n",
    "    # 11. ANOMALY FLAGS \n",
    "    df['extreme_dti'] = (df['debt_to_income_ratio'] > df['debt_to_income_ratio'].quantile(0.95)).astype(int)\n",
    "    df['low_income'] = (df['annual_income'] < df['annual_income'].quantile(0.25)).astype(int)\n",
    "    df['large_loan'] = (df['loan_amount'] > df['loan_amount'].quantile(0.75)).astype(int)\n",
    "    df['risky_combo_1'] = ((df['debt_to_income_ratio'] > 0.4) & (df['credit_score'] < 600)).astype(int)\n",
    "    df['risky_combo_2'] = ((df['loan_to_income_ratio'] > 0.5) & (df['interest_rate'] > 15)).astype(int)\n",
    "    df['safe_combo'] = ((df['credit_score'] > 750) & (df['debt_to_income_ratio'] < 0.1)).astype(int)\n",
    "    df['high_risk_all'] = (df['extreme_dti'] & df['risky_combo_1']).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e2bd69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T05:52:34.510987Z",
     "iopub.status.busy": "2025-11-08T05:52:34.510287Z",
     "iopub.status.idle": "2025-11-08T05:52:43.331989Z",
     "shell.execute_reply": "2025-11-08T05:52:43.330881Z"
    },
    "papermill": {
     "duration": 8.827359,
     "end_time": "2025-11-08T05:52:43.333871",
     "exception": false,
     "start_time": "2025-11-08T05:52:34.506512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3. Applying Feature Engineering & Encoding ---\n",
      "\n",
      "ENCODING CATEGORICAL FEATURES\n",
      "✓ gender: 3 classes\n",
      "✓ marital_status: 4 classes\n",
      "✓ education_level: 5 classes\n",
      "✓ employment_status: 5 classes\n",
      "✓ loan_purpose: 8 classes\n",
      "✓ grade_subgrade: 30 classes\n",
      "✓ credit_category: 5 classes\n",
      "✓ loan_size: 4 classes\n",
      "✓ grade: 6 classes\n",
      "✓ gender_marital: 12 classes\n",
      "✓ education_employment: 25 classes\n",
      "✓ gender_education: 15 classes\n",
      "✓ marital_employment: 20 classes\n",
      "✓ purpose_grade: 48 classes\n",
      "✓ employment_purpose: 40 classes\n",
      "\n",
      "FINAL DATA READY\n",
      "X: (593994, 84)\n",
      "y: (593994,)\n",
      "X_test: (254569, 84)\n",
      "Features: 84\n",
      "\n",
      "--- 4. Model Training (LGBM) ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 3. Applying Feature Engineering & Encoding ---\")\n",
    "\n",
    "# Apply feature engineering \n",
    "train_fe = complete_feature_engineering(train)\n",
    "test_fe = complete_feature_engineering(test)\n",
    "\n",
    "# Encode categorical features \n",
    "print(\"\\nENCODING CATEGORICAL FEATURES\")\n",
    "categorical_features = train_fe.select_dtypes(include=['object', 'category']).columns\n",
    "le_dict = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    # Combine train and test for a full fit, ensuring all categories are known\n",
    "    all_values = pd.concat([train_fe[col].astype(str), test_fe[col].astype(str)])\n",
    "    le.fit(all_values)\n",
    "    \n",
    "    train_fe[col] = le.transform(train_fe[col].astype(str))\n",
    "    test_fe[col] = le.transform(test_fe[col].astype(str))\n",
    "    le_dict[col] = le\n",
    "    print(f\"✓ {col}: {len(le.classes_)} classes\")\n",
    "\n",
    "# Prepare final datasets \n",
    "print(\"\\nFINAL DATA READY\")\n",
    "feature_cols = [col for col in train_fe.columns if col not in ['id', config.TARGET]]\n",
    "\n",
    "# Align columns - crucial if FE created different columns\n",
    "train_cols = set(train_fe.columns)\n",
    "test_cols = set(test_fe.columns)\n",
    "\n",
    "missing_in_test = list(train_cols - test_cols - {'id', config.TARGET})\n",
    "for col in missing_in_test:\n",
    "    if col in feature_cols:\n",
    "        test_fe[col] = 0 \n",
    "\n",
    "missing_in_train = list(test_cols - train_cols - {'id'})\n",
    "for col in missing_in_train:\n",
    "    if col in feature_cols:\n",
    "        train_fe[col] = 0\n",
    "\n",
    "# Ensure final feature list is identical\n",
    "feature_cols = [col for col in feature_cols if col in test_fe.columns]\n",
    "X = train_fe[feature_cols]\n",
    "y = train_fe[config.TARGET]\n",
    "X_test = test_fe[feature_cols]\n",
    "test_ids = test_fe['id']\n",
    "\n",
    "# Fill any remaining NaNs from FE (e.g., from ratios)\n",
    "X = X.fillna(-1)\n",
    "X_test = X_test.fillna(-1)\n",
    "\n",
    "print(f\"X: {X.shape}\")\n",
    "print(f\"y: {y.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(\"\\n--- 4. Model Training (LGBM) ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abdc92cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T05:52:43.345247Z",
     "iopub.status.busy": "2025-11-08T05:52:43.344499Z",
     "iopub.status.idle": "2025-11-08T05:52:43.355931Z",
     "shell.execute_reply": "2025-11-08T05:52:43.355176Z"
    },
    "papermill": {
     "duration": 0.017331,
     "end_time": "2025-11-08T05:52:43.357245",
     "exception": false,
     "start_time": "2025-11-08T05:52:43.339914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_lightgbm(X, y, X_test, n_splits=5):\n",
    "    \"\"\" Trains LightGBM model using StratifiedKFold \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=config.SEED)\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # Parameters from source notebook \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'max_depth': -1,\n",
    "        'min_child_samples': 20,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 0.1,\n",
    "        'random_state': config.SEED,\n",
    "        'verbose': -1,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\n--- Fold {fold + 1}/{n_splits} ---\")\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=2000,\n",
    "            valid_sets=[train_data, val_data],\n",
    "            callbacks=[lgb.early_stopping(100), lgb.log_evaluation(200)]\n",
    "        ) \n",
    "        \n",
    "        val_preds = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        oof_preds[val_idx] = val_preds\n",
    "        test_preds += model.predict(X_test, num_iteration=model.best_iteration) / n_splits \n",
    "        \n",
    "        score = roc_auc_score(y_val, val_preds) \n",
    "        fold_scores.append(score)\n",
    "        print(f\"Fold {fold + 1} AUC: {score:.6f}\")\n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = X.columns\n",
    "        fold_importance_df[\"importance\"] = model.feature_importance(importance_type='gain') \n",
    "        fold_importance_df[\"fold\"] = fold + 1\n",
    "        feature_importance = pd.concat([feature_importance, fold_importance_df], axis=0)\n",
    "\n",
    "    overall_score = roc_auc_score(y, oof_preds)\n",
    "    print(f\"\\nLightGBM OOF AUC: {overall_score:.6f}\")\n",
    "    print(f\"Mean: {np.mean(fold_scores):.6f} (+/- {np.std(fold_scores):.6f})\")\n",
    "    return oof_preds, test_preds, feature_importance, overall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ff18b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T05:52:43.366065Z",
     "iopub.status.busy": "2025-11-08T05:52:43.365422Z",
     "iopub.status.idle": "2025-11-08T06:00:53.223477Z",
     "shell.execute_reply": "2025-11-08T06:00:53.222261Z"
    },
    "papermill": {
     "duration": 489.863733,
     "end_time": "2025-11-08T06:00:53.224859",
     "exception": false,
     "start_time": "2025-11-08T05:52:43.361126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LightGBM...\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's auc: 0.922442\tvalid_1's auc: 0.920568\n",
      "[400]\ttraining's auc: 0.927888\tvalid_1's auc: 0.921743\n",
      "[600]\ttraining's auc: 0.932566\tvalid_1's auc: 0.922435\n",
      "[800]\ttraining's auc: 0.936837\tvalid_1's auc: 0.922586\n",
      "[1000]\ttraining's auc: 0.940291\tvalid_1's auc: 0.922635\n",
      "Early stopping, best iteration is:\n",
      "[938]\ttraining's auc: 0.939342\tvalid_1's auc: 0.922691\n",
      "Fold 1 AUC: 0.922691\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's auc: 0.922359\tvalid_1's auc: 0.91966\n",
      "[400]\ttraining's auc: 0.928167\tvalid_1's auc: 0.921101\n",
      "[600]\ttraining's auc: 0.932599\tvalid_1's auc: 0.921701\n",
      "Early stopping, best iteration is:\n",
      "[631]\ttraining's auc: 0.933185\tvalid_1's auc: 0.921781\n",
      "Fold 2 AUC: 0.921781\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's auc: 0.923076\tvalid_1's auc: 0.918779\n",
      "[400]\ttraining's auc: 0.928423\tvalid_1's auc: 0.919877\n",
      "[600]\ttraining's auc: 0.932904\tvalid_1's auc: 0.920312\n",
      "[800]\ttraining's auc: 0.936921\tvalid_1's auc: 0.920498\n",
      "Early stopping, best iteration is:\n",
      "[747]\ttraining's auc: 0.935897\tvalid_1's auc: 0.920619\n",
      "Fold 3 AUC: 0.920619\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's auc: 0.922797\tvalid_1's auc: 0.919481\n",
      "[400]\ttraining's auc: 0.928375\tvalid_1's auc: 0.920635\n",
      "[600]\ttraining's auc: 0.932944\tvalid_1's auc: 0.921098\n",
      "[800]\ttraining's auc: 0.936856\tvalid_1's auc: 0.921253\n",
      "Early stopping, best iteration is:\n",
      "[835]\ttraining's auc: 0.937522\tvalid_1's auc: 0.9213\n",
      "Fold 4 AUC: 0.921300\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's auc: 0.922951\tvalid_1's auc: 0.919204\n",
      "[400]\ttraining's auc: 0.928501\tvalid_1's auc: 0.920553\n",
      "[600]\ttraining's auc: 0.932888\tvalid_1's auc: 0.92081\n",
      "Early stopping, best iteration is:\n",
      "[680]\ttraining's auc: 0.934556\tvalid_1's auc: 0.920939\n",
      "Fold 5 AUC: 0.920939\n",
      "\n",
      "LightGBM OOF AUC: 0.921461\n",
      "Mean: 0.921466 (+/- 0.000724)\n",
      "\n",
      "--- 5. Model Training (XGBoost) ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining LightGBM...\")\n",
    "lgb_oof, lgb_test, lgb_importance, lgb_score = train_lightgbm(X, y, X_test, n_splits=config.N_SPLITS)\n",
    "print(\"\\n--- 5. Model Training (XGBoost) ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75310cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T06:00:53.237467Z",
     "iopub.status.busy": "2025-11-08T06:00:53.237141Z",
     "iopub.status.idle": "2025-11-08T06:00:53.245682Z",
     "shell.execute_reply": "2025-11-08T06:00:53.245000Z"
    },
    "papermill": {
     "duration": 0.016094,
     "end_time": "2025-11-08T06:00:53.246872",
     "exception": false,
     "start_time": "2025-11-08T06:00:53.230778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_xgboost(X, y, X_test, n_splits=5):\n",
    "    \"\"\" Trains XGBoost model using StratifiedKFold\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=config.SEED)\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    \n",
    "    # Parameters from source notebook \n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.05,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'min_child_weight': 1,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 0.1,\n",
    "        'random_state': config.SEED,\n",
    "        'tree_method': 'hist',\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\n--- Fold {fold + 1}/{n_splits} ---\")\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = xgb.XGBClassifier(**params, n_estimators=2000) \n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=200\n",
    "        ) \n",
    "        \n",
    "        val_preds = model.predict_proba(X_val)[:, 1]\n",
    "        oof_preds[val_idx] = val_preds\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / n_splits \n",
    "        \n",
    "        score = roc_auc_score(y_val, val_preds) \n",
    "        fold_scores.append(score)\n",
    "        print(f\"Fold {fold + 1} AUC: {score:.6f}\")\n",
    "\n",
    "    overall_score = roc_auc_score(y, oof_preds) \n",
    "    print(f\"\\nXGBoost OOF AUC: {overall_score:.6f}\")\n",
    "    print(f\"Mean: {np.mean(fold_scores):.6f} (+/- {np.std(fold_scores):.6f})\")\n",
    "    return oof_preds, test_preds, overall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "300108be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T06:00:53.258610Z",
     "iopub.status.busy": "2025-11-08T06:00:53.258352Z",
     "iopub.status.idle": "2025-11-08T06:10:27.751628Z",
     "shell.execute_reply": "2025-11-08T06:10:27.750435Z"
    },
    "papermill": {
     "duration": 574.500794,
     "end_time": "2025-11-08T06:10:27.753176",
     "exception": false,
     "start_time": "2025-11-08T06:00:53.252382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost...\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[0]\tvalidation_0-auc:0.90833\n",
      "[200]\tvalidation_0-auc:0.91925\n",
      "[400]\tvalidation_0-auc:0.92142\n",
      "[600]\tvalidation_0-auc:0.92198\n",
      "[776]\tvalidation_0-auc:0.92207\n",
      "Fold 1 AUC: 0.922122\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[0]\tvalidation_0-auc:0.90679\n",
      "[200]\tvalidation_0-auc:0.91852\n",
      "[400]\tvalidation_0-auc:0.92065\n",
      "[600]\tvalidation_0-auc:0.92140\n",
      "[772]\tvalidation_0-auc:0.92146\n",
      "Fold 2 AUC: 0.921505\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[0]\tvalidation_0-auc:0.90673\n",
      "[200]\tvalidation_0-auc:0.91692\n",
      "[400]\tvalidation_0-auc:0.91900\n",
      "[600]\tvalidation_0-auc:0.91959\n",
      "[800]\tvalidation_0-auc:0.91970\n",
      "[965]\tvalidation_0-auc:0.91966\n",
      "Fold 3 AUC: 0.919772\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[0]\tvalidation_0-auc:0.90693\n",
      "[200]\tvalidation_0-auc:0.91814\n",
      "[400]\tvalidation_0-auc:0.92006\n",
      "[600]\tvalidation_0-auc:0.92067\n",
      "[800]\tvalidation_0-auc:0.92088\n",
      "[950]\tvalidation_0-auc:0.92083\n",
      "Fold 4 AUC: 0.920934\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[0]\tvalidation_0-auc:0.90723\n",
      "[200]\tvalidation_0-auc:0.91757\n",
      "[400]\tvalidation_0-auc:0.91968\n",
      "[600]\tvalidation_0-auc:0.92023\n",
      "[800]\tvalidation_0-auc:0.92026\n",
      "[919]\tvalidation_0-auc:0.92027\n",
      "Fold 5 AUC: 0.920333\n",
      "\n",
      "XGBoost OOF AUC: 0.920922\n",
      "Mean: 0.920933 (+/- 0.000830)\n",
      "\n",
      "--- 6. Model Training (CatBoost) ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining XGBoost...\")\n",
    "xgb_oof, xgb_test, xgb_score = train_xgboost(X, y, X_test, n_splits=config.N_SPLITS)\n",
    "print(\"\\n--- 6. Model Training (CatBoost) ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "380db1e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T06:10:27.769092Z",
     "iopub.status.busy": "2025-11-08T06:10:27.768381Z",
     "iopub.status.idle": "2025-11-08T06:10:27.793248Z",
     "shell.execute_reply": "2025-11-08T06:10:27.792349Z"
    },
    "papermill": {
     "duration": 0.034217,
     "end_time": "2025-11-08T06:10:27.794753",
     "exception": false,
     "start_time": "2025-11-08T06:10:27.760536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_catboost(X, y, X_test, n_splits=5):\n",
    "    \"\"\" Trains CatBoost model using StratifiedKFold\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=config.SEED) \n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    \n",
    "    # Parameters from source notebook \n",
    "    params = {\n",
    "        'iterations': 2000,\n",
    "        'learning_rate': 0.05,\n",
    "        'depth': 6,\n",
    "        'l2_leaf_reg': 3,\n",
    "        'random_seed': config.SEED,\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'early_stopping_rounds': 100,\n",
    "        'verbose': 200,\n",
    "        'task_type': 'CPU' # Source notebook uses CPU\n",
    "    }\n",
    "    \n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\n--- Fold {fold + 1}/{n_splits} ---\")\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = CatBoostClassifier(**params) \n",
    "        model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True) \n",
    "        \n",
    "        val_preds = model.predict_proba(X_val)[:, 1] \n",
    "        oof_preds[val_idx] = val_preds\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / n_splits \n",
    "        \n",
    "        score = roc_auc_score(y_val, val_preds) \n",
    "        fold_scores.append(score)\n",
    "        print(f\"Fold {fold + 1} AUC: {score:.6f}\")\n",
    "\n",
    "    overall_score = roc_auc_score(y, oof_preds) \n",
    "    print(f\"\\nCatBoost OOF AUC: {overall_score:.6f}\")\n",
    "    print(f\"Mean: {np.mean(fold_scores):.6f} (+/- {np.std(fold_scores):.6f})\")\n",
    "    return oof_preds, test_preds, overall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b22a2ca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T06:10:27.810055Z",
     "iopub.status.busy": "2025-11-08T06:10:27.809806Z",
     "iopub.status.idle": "2025-11-08T06:28:31.080041Z",
     "shell.execute_reply": "2025-11-08T06:28:31.078759Z"
    },
    "papermill": {
     "duration": 1083.279819,
     "end_time": "2025-11-08T06:28:31.081717",
     "exception": false,
     "start_time": "2025-11-08T06:10:27.801898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CatBoost...\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "0:\ttest: 0.9022510\tbest: 0.9022510 (0)\ttotal: 178ms\tremaining: 5m 56s\n",
      "200:\ttest: 0.9166465\tbest: 0.9166465 (200)\ttotal: 21.1s\tremaining: 3m 8s\n",
      "400:\ttest: 0.9190007\tbest: 0.9190007 (400)\ttotal: 41.2s\tremaining: 2m 44s\n",
      "600:\ttest: 0.9202509\tbest: 0.9202509 (600)\ttotal: 1m 1s\tremaining: 2m 23s\n",
      "800:\ttest: 0.9209301\tbest: 0.9209302 (798)\ttotal: 1m 22s\tremaining: 2m 2s\n",
      "1000:\ttest: 0.9215918\tbest: 0.9215918 (1000)\ttotal: 1m 42s\tremaining: 1m 42s\n",
      "1200:\ttest: 0.9219187\tbest: 0.9219188 (1198)\ttotal: 2m 3s\tremaining: 1m 21s\n",
      "1400:\ttest: 0.9221681\tbest: 0.9221732 (1393)\ttotal: 2m 23s\tremaining: 1m 1s\n",
      "1600:\ttest: 0.9224090\tbest: 0.9224090 (1600)\ttotal: 2m 44s\tremaining: 40.9s\n",
      "1800:\ttest: 0.9225697\tbest: 0.9225697 (1800)\ttotal: 3m 4s\tremaining: 20.4s\n",
      "1999:\ttest: 0.9226961\tbest: 0.9226968 (1997)\ttotal: 3m 25s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9226967803\n",
      "bestIteration = 1997\n",
      "\n",
      "Shrink model to first 1998 iterations.\n",
      "Fold 1 AUC: 0.922697\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "0:\ttest: 0.9023162\tbest: 0.9023162 (0)\ttotal: 108ms\tremaining: 3m 35s\n",
      "200:\ttest: 0.9160644\tbest: 0.9160644 (200)\ttotal: 21s\tremaining: 3m 8s\n",
      "400:\ttest: 0.9184948\tbest: 0.9184949 (399)\ttotal: 41.4s\tremaining: 2m 44s\n",
      "600:\ttest: 0.9196654\tbest: 0.9196654 (600)\ttotal: 1m 1s\tremaining: 2m 23s\n",
      "800:\ttest: 0.9205471\tbest: 0.9205471 (800)\ttotal: 1m 21s\tremaining: 2m 2s\n",
      "1000:\ttest: 0.9209918\tbest: 0.9209922 (999)\ttotal: 1m 42s\tremaining: 1m 42s\n",
      "1200:\ttest: 0.9215138\tbest: 0.9215138 (1200)\ttotal: 2m 2s\tremaining: 1m 21s\n",
      "1400:\ttest: 0.9218013\tbest: 0.9218013 (1400)\ttotal: 2m 23s\tremaining: 1m 1s\n",
      "1600:\ttest: 0.9220076\tbest: 0.9220076 (1600)\ttotal: 2m 44s\tremaining: 41s\n",
      "1800:\ttest: 0.9221596\tbest: 0.9221596 (1800)\ttotal: 3m 4s\tremaining: 20.4s\n",
      "1999:\ttest: 0.9223127\tbest: 0.9223127 (1999)\ttotal: 3m 25s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.922312679\n",
      "bestIteration = 1999\n",
      "\n",
      "Fold 2 AUC: 0.922313\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "0:\ttest: 0.9001268\tbest: 0.9001268 (0)\ttotal: 106ms\tremaining: 3m 31s\n",
      "200:\ttest: 0.9147979\tbest: 0.9147979 (200)\ttotal: 21.1s\tremaining: 3m 8s\n",
      "400:\ttest: 0.9170988\tbest: 0.9170988 (400)\ttotal: 41.2s\tremaining: 2m 44s\n",
      "600:\ttest: 0.9182407\tbest: 0.9182407 (600)\ttotal: 1m 1s\tremaining: 2m 24s\n",
      "800:\ttest: 0.9190087\tbest: 0.9190092 (799)\ttotal: 1m 22s\tremaining: 2m 3s\n",
      "1000:\ttest: 0.9194972\tbest: 0.9194972 (1000)\ttotal: 1m 43s\tremaining: 1m 43s\n",
      "1200:\ttest: 0.9199853\tbest: 0.9199918 (1190)\ttotal: 2m 4s\tremaining: 1m 22s\n",
      "1400:\ttest: 0.9202397\tbest: 0.9202403 (1399)\ttotal: 2m 25s\tremaining: 1m 2s\n",
      "1600:\ttest: 0.9204282\tbest: 0.9204390 (1591)\ttotal: 2m 46s\tremaining: 41.5s\n",
      "1800:\ttest: 0.9205645\tbest: 0.9205698 (1794)\ttotal: 3m 7s\tremaining: 20.8s\n",
      "1999:\ttest: 0.9206759\tbest: 0.9206772 (1997)\ttotal: 3m 28s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9206772067\n",
      "bestIteration = 1997\n",
      "\n",
      "Shrink model to first 1998 iterations.\n",
      "Fold 3 AUC: 0.920677\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "0:\ttest: 0.9006072\tbest: 0.9006072 (0)\ttotal: 107ms\tremaining: 3m 33s\n",
      "200:\ttest: 0.9155320\tbest: 0.9155320 (200)\ttotal: 22.2s\tremaining: 3m 18s\n",
      "400:\ttest: 0.9180183\tbest: 0.9180183 (400)\ttotal: 45.6s\tremaining: 3m 2s\n",
      "600:\ttest: 0.9191428\tbest: 0.9191446 (599)\ttotal: 1m 7s\tremaining: 2m 38s\n",
      "800:\ttest: 0.9200291\tbest: 0.9200298 (795)\ttotal: 1m 30s\tremaining: 2m 16s\n",
      "1000:\ttest: 0.9204769\tbest: 0.9204769 (1000)\ttotal: 1m 55s\tremaining: 1m 55s\n",
      "1200:\ttest: 0.9208387\tbest: 0.9208412 (1193)\ttotal: 2m 18s\tremaining: 1m 32s\n",
      "1400:\ttest: 0.9210745\tbest: 0.9210775 (1388)\ttotal: 2m 40s\tremaining: 1m 8s\n",
      "1600:\ttest: 0.9212991\tbest: 0.9212991 (1600)\ttotal: 3m 4s\tremaining: 45.9s\n",
      "1800:\ttest: 0.9214484\tbest: 0.9214515 (1793)\ttotal: 3m 27s\tremaining: 22.9s\n",
      "1999:\ttest: 0.9215817\tbest: 0.9215839 (1960)\ttotal: 3m 50s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9215838764\n",
      "bestIteration = 1960\n",
      "\n",
      "Shrink model to first 1961 iterations.\n",
      "Fold 4 AUC: 0.921584\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "0:\ttest: 0.9010101\tbest: 0.9010101 (0)\ttotal: 119ms\tremaining: 3m 58s\n",
      "200:\ttest: 0.9152413\tbest: 0.9152413 (200)\ttotal: 22s\tremaining: 3m 17s\n",
      "400:\ttest: 0.9175739\tbest: 0.9175739 (400)\ttotal: 43.1s\tremaining: 2m 52s\n",
      "600:\ttest: 0.9187326\tbest: 0.9187326 (600)\ttotal: 1m 4s\tremaining: 2m 30s\n",
      "800:\ttest: 0.9194385\tbest: 0.9194398 (799)\ttotal: 1m 26s\tremaining: 2m 9s\n",
      "1000:\ttest: 0.9199161\tbest: 0.9199212 (993)\ttotal: 1m 49s\tremaining: 1m 49s\n",
      "1200:\ttest: 0.9202181\tbest: 0.9202221 (1194)\ttotal: 2m 11s\tremaining: 1m 27s\n",
      "1400:\ttest: 0.9204521\tbest: 0.9204531 (1398)\ttotal: 2m 34s\tremaining: 1m 5s\n",
      "1600:\ttest: 0.9206681\tbest: 0.9206790 (1592)\ttotal: 2m 55s\tremaining: 43.6s\n",
      "1800:\ttest: 0.9207619\tbest: 0.9207637 (1798)\ttotal: 3m 16s\tremaining: 21.7s\n",
      "1999:\ttest: 0.9208691\tbest: 0.9208691 (1999)\ttotal: 3m 39s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9208690996\n",
      "bestIteration = 1999\n",
      "\n",
      "Fold 5 AUC: 0.920869\n",
      "\n",
      "CatBoost OOF AUC: 0.921624\n",
      "Mean: 0.921628 (+/- 0.000787)\n",
      "\n",
      "--- 7. Model Evaluation & Ensemble ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining CatBoost...\")\n",
    "cat_oof, cat_test, cat_score = train_catboost(X, y, X_test, n_splits=config.N_SPLITS)\n",
    "print(\"\\n--- 7. Model Evaluation & Ensemble ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d51ce2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T06:28:31.103943Z",
     "iopub.status.busy": "2025-11-08T06:28:31.103634Z",
     "iopub.status.idle": "2025-11-08T06:28:32.336916Z",
     "shell.execute_reply": "2025-11-08T06:28:32.335831Z"
    },
    "papermill": {
     "duration": 1.246547,
     "end_time": "2025-11-08T06:28:32.338467",
     "exception": false,
     "start_time": "2025-11-08T06:28:31.091920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL COMPARISON\n",
      "      Model   OOF AUC\n",
      "2  CatBoost  0.921624\n",
      "0  LightGBM  0.921461\n",
      "1   XGBoost  0.920922\n",
      "\n",
      "CREATING ENSEMBLE\n",
      "\n",
      "Ensemble Results:\n",
      "           Ensemble   OOF AUC\n",
      "2      Rank Average  0.921893\n",
      "1  Weighted Average  0.921865\n",
      "0    Simple Average  0.921865\n",
      "\n",
      "Weights: LGB=0.333, XGB=0.333, CAT=0.333\n",
      "\n",
      "Best Ensemble: Rank Average (AUC: 0.921893)\n",
      "\n",
      "--- 8. Submission ---\n"
     ]
    }
   ],
   "source": [
    "# Model Comparison \n",
    "print(\"\\nMODEL COMPARISON\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['LightGBM', 'XGBoost', 'CatBoost'],\n",
    "    'OOF AUC': [lgb_score, xgb_score, cat_score]\n",
    "}).sort_values('OOF AUC', ascending=False)\n",
    "print(comparison)\n",
    "\n",
    "# Create Ensemble \n",
    "print(\"\\nCREATING ENSEMBLE\")\n",
    "\n",
    "# 1. Simple Average\n",
    "simple_oof = (lgb_oof + xgb_oof + cat_oof) / 3\n",
    "simple_test = (lgb_test + xgb_test + cat_test) / 3\n",
    "simple_score = roc_auc_score(y, simple_oof)\n",
    "\n",
    "# 2. Weighted Average \n",
    "total_auc = lgb_score + xgb_score + cat_score\n",
    "w_lgb = lgb_score / total_auc\n",
    "w_xgb = xgb_score / total_auc\n",
    "w_cat = cat_score / total_auc\n",
    "weighted_oof = (lgb_oof * w_lgb) + (xgb_oof * w_xgb) + (cat_oof * w_cat)\n",
    "weighted_test = (lgb_test * w_lgb) + (xgb_test * w_xgb) + (cat_test * w_cat)\n",
    "weighted_score = roc_auc_score(y, weighted_oof)\n",
    "\n",
    "# 3. Rank Average \n",
    "rank_oof = (rankdata(lgb_oof) + rankdata(xgb_oof) + rankdata(cat_oof)) / (3 * len(lgb_oof))\n",
    "rank_test = (rankdata(lgb_test) + rankdata(xgb_test) + rankdata(cat_test)) / (3 * len(lgb_test))\n",
    "rank_score = roc_auc_score(y, rank_oof)\n",
    "\n",
    "# Ensemble Results\n",
    "ensemble_results = pd.DataFrame({\n",
    "    'Ensemble': ['Simple Average', 'Weighted Average', 'Rank Average'],\n",
    "    'OOF AUC': [simple_score, weighted_score, rank_score]\n",
    "}).sort_values('OOF AUC', ascending=False) \n",
    "\n",
    "print(\"\\nEnsemble Results:\")\n",
    "print(ensemble_results)\n",
    "print(f\"\\nWeights: LGB={w_lgb:.3f}, XGB={w_xgb:.3f}, CAT={w_cat:.3f}\") \n",
    "\n",
    "# Choose best\n",
    "best_idx = ensemble_results['OOF AUC'].idxmax()\n",
    "best_name = ensemble_results.loc[best_idx, 'Ensemble']\n",
    "best_score = ensemble_results.loc[best_idx, 'OOF AUC']\n",
    "\n",
    "if best_name == 'Simple Average':\n",
    "    final_preds = simple_test\n",
    "elif best_name == 'Weighted Average':\n",
    "    final_preds = weighted_test\n",
    "else:\n",
    "    final_preds = rank_test \n",
    "\n",
    "print(f\"\\nBest Ensemble: {best_name} (AUC: {best_score:.6f})\") \n",
    "print(\"\\n--- 8. Submission ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3147d1d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T06:28:32.360217Z",
     "iopub.status.busy": "2025-11-08T06:28:32.359880Z",
     "iopub.status.idle": "2025-11-08T06:28:32.974939Z",
     "shell.execute_reply": "2025-11-08T06:28:32.973199Z"
    },
    "papermill": {
     "duration": 0.628034,
     "end_time": "2025-11-08T06:28:32.976802",
     "exception": false,
     "start_time": "2025-11-08T06:28:32.348768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBMISSION CREATED\n",
      "File: submission.csv\n",
      "Shape: (254569, 2)\n",
      "\n",
      "Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loan_paid_back</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593994</td>\n",
       "      <td>0.499309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593995</td>\n",
       "      <td>0.788466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593996</td>\n",
       "      <td>0.128066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593997</td>\n",
       "      <td>0.506112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593998</td>\n",
       "      <td>0.623759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>593999</td>\n",
       "      <td>0.727296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>594000</td>\n",
       "      <td>0.834262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>594001</td>\n",
       "      <td>0.661948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>594002</td>\n",
       "      <td>0.526185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>594003</td>\n",
       "      <td>0.018947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  loan_paid_back\n",
       "0  593994        0.499309\n",
       "1  593995        0.788466\n",
       "2  593996        0.128066\n",
       "3  593997        0.506112\n",
       "4  593998        0.623759\n",
       "5  593999        0.727296\n",
       "6  594000        0.834262\n",
       "7  594001        0.661948\n",
       "8  594002        0.526185\n",
       "9  594003        0.018947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create submission\n",
    "# (Uncommented from source to generate the file as per 'Version' format)\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    config.TARGET: final_preds\n",
    "}) \n",
    "\n",
    "submission.to_csv('submission.csv', index=False) \n",
    "print(\"SUBMISSION CREATED\") \n",
    "print(f\"File: submission.csv\") \n",
    "print(f\"Shape: {submission.shape}\") \n",
    "print(f\"\\nPreview:\")\n",
    "display(submission.head(10)) "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14262372,
     "sourceId": 91722,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2176.698005,
   "end_time": "2025-11-08T06:28:34.112632",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-08T05:52:17.414627",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
